{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Python - Project 1\n",
    "\n",
    "Due Friday, March 6th by 5 pm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "### 1.1 Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional libraries or submodules below\n",
    "\n",
    "# Display plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Data libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting defaults\n",
    "plt.rcParams['figure.figsize'] = (8,5)\n",
    "plt.rcParams['figure.dpi'] = 80\n",
    "\n",
    "# sklearn modules\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, KBinsDiscretizer\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv(\"sales.csv\")\n",
    "sales_test = pd.read_csv(\"sales_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Include a discussion of the data with a particular emphasis on the features of the data that are relevant for the subsequent modeling. Including visualizations of the data is strongly encouraged - all code and plots must also be described in the write up.*\n",
    "\n",
    "*In this section you should also implement and describe any preprocessing / transformations of the features. Hint - you should not be modeling this data without transforming some of the features, e.g. modeling sale price directly is not a good idea.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 A glimpse on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at a few rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_price</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>year_built</th>\n",
       "      <th>lot_area</th>\n",
       "      <th>basement_area</th>\n",
       "      <th>living_area</th>\n",
       "      <th>full_bath</th>\n",
       "      <th>half_bath</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>garage_cars</th>\n",
       "      <th>garage_area</th>\n",
       "      <th>ac</th>\n",
       "      <th>zoning</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>quality</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>244000</td>\n",
       "      <td>2010</td>\n",
       "      <td>1968</td>\n",
       "      <td>11160</td>\n",
       "      <td>2110</td>\n",
       "      <td>2110</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>522</td>\n",
       "      <td>Y</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>nb_07</td>\n",
       "      <td>good</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189900</td>\n",
       "      <td>2010</td>\n",
       "      <td>1997</td>\n",
       "      <td>13830</td>\n",
       "      <td>928</td>\n",
       "      <td>1629</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>482</td>\n",
       "      <td>Y</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>nb_22</td>\n",
       "      <td>average</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191500</td>\n",
       "      <td>2010</td>\n",
       "      <td>1992</td>\n",
       "      <td>5005</td>\n",
       "      <td>1280</td>\n",
       "      <td>1280</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>506</td>\n",
       "      <td>Y</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>nb_10</td>\n",
       "      <td>good</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>236500</td>\n",
       "      <td>2010</td>\n",
       "      <td>1995</td>\n",
       "      <td>5389</td>\n",
       "      <td>1595</td>\n",
       "      <td>1616</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>Y</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>nb_10</td>\n",
       "      <td>good</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189000</td>\n",
       "      <td>2010</td>\n",
       "      <td>1999</td>\n",
       "      <td>7500</td>\n",
       "      <td>994</td>\n",
       "      <td>1804</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>442</td>\n",
       "      <td>Y</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>nb_22</td>\n",
       "      <td>good</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>79500</td>\n",
       "      <td>2006</td>\n",
       "      <td>1970</td>\n",
       "      <td>1526</td>\n",
       "      <td>546</td>\n",
       "      <td>1092</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Residential_Medium_Density</td>\n",
       "      <td>nb_02</td>\n",
       "      <td>average</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>160000</td>\n",
       "      <td>2006</td>\n",
       "      <td>1977</td>\n",
       "      <td>17400</td>\n",
       "      <td>1126</td>\n",
       "      <td>1126</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>484</td>\n",
       "      <td>Y</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>nb_20</td>\n",
       "      <td>average</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>142500</td>\n",
       "      <td>2006</td>\n",
       "      <td>1984</td>\n",
       "      <td>7937</td>\n",
       "      <td>1003</td>\n",
       "      <td>1003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>588</td>\n",
       "      <td>Y</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>nb_20</td>\n",
       "      <td>average</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>132000</td>\n",
       "      <td>2006</td>\n",
       "      <td>1992</td>\n",
       "      <td>10441</td>\n",
       "      <td>912</td>\n",
       "      <td>970</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>nb_20</td>\n",
       "      <td>average</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>170000</td>\n",
       "      <td>2006</td>\n",
       "      <td>1974</td>\n",
       "      <td>10010</td>\n",
       "      <td>1389</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>418</td>\n",
       "      <td>Y</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>nb_20</td>\n",
       "      <td>average</td>\n",
       "      <td>average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1584 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sale_price  year_sold  year_built  lot_area  basement_area  living_area  \\\n",
       "0         244000       2010        1968     11160           2110         2110   \n",
       "1         189900       2010        1997     13830            928         1629   \n",
       "2         191500       2010        1992      5005           1280         1280   \n",
       "3         236500       2010        1995      5389           1595         1616   \n",
       "4         189000       2010        1999      7500            994         1804   \n",
       "...          ...        ...         ...       ...            ...          ...   \n",
       "1579       79500       2006        1970      1526            546         1092   \n",
       "1580      160000       2006        1977     17400           1126         1126   \n",
       "1581      142500       2006        1984      7937           1003         1003   \n",
       "1582      132000       2006        1992     10441            912          970   \n",
       "1583      170000       2006        1974     10010           1389         1389   \n",
       "\n",
       "      full_bath  half_bath  bedroom  garage_cars  garage_area ac  \\\n",
       "0             2          1        3            2          522  Y   \n",
       "1             2          1        3            2          482  Y   \n",
       "2             2          0        2            2          506  Y   \n",
       "3             2          0        2            2          608  Y   \n",
       "4             2          1        3            2          442  Y   \n",
       "...         ...        ...      ...          ...          ... ..   \n",
       "1579          1          1        3            0            0  Y   \n",
       "1580          2          0        3            2          484  Y   \n",
       "1581          1          0        3            2          588  Y   \n",
       "1582          1          0        3            0            0  Y   \n",
       "1583          1          0        2            2          418  Y   \n",
       "\n",
       "                          zoning neighborhood  quality condition  \n",
       "0        Residential_Low_Density        nb_07     good   average  \n",
       "1        Residential_Low_Density        nb_22  average   average  \n",
       "2        Residential_Low_Density        nb_10     good   average  \n",
       "3        Residential_Low_Density        nb_10     good   average  \n",
       "4        Residential_Low_Density        nb_22     good   average  \n",
       "...                          ...          ...      ...       ...  \n",
       "1579  Residential_Medium_Density        nb_02  average   average  \n",
       "1580     Residential_Low_Density        nb_20  average   average  \n",
       "1581     Residential_Low_Density        nb_20  average   average  \n",
       "1582     Residential_Low_Density        nb_20  average   average  \n",
       "1583     Residential_Low_Density        nb_20  average   average  \n",
       "\n",
       "[1584 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the datatypes of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sale_price        int64\n",
       "year_sold         int64\n",
       "year_built        int64\n",
       "lot_area          int64\n",
       "basement_area     int64\n",
       "living_area       int64\n",
       "full_bath         int64\n",
       "half_bath         int64\n",
       "bedroom           int64\n",
       "garage_cars       int64\n",
       "garage_area       int64\n",
       "ac               object\n",
       "zoning           object\n",
       "neighborhood     object\n",
       "quality          object\n",
       "condition        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column `ac`, `zoning`, `neighborhood`, `quality`, and `condition` are apparent categorical variables to be encoded. This is also mentioned in the `README.ipynb` file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Transform categorical variables using one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I would like to discuss how I would transform the categorical variables of this dataset, with rules specified in the `encoding` dictionary.\n",
    "\n",
    "All the categorical features except `neighborhood` can be easily transformed. However, I decide to sort the `neighborhood` by their means. I will then transform it into an ordinal feature so that this feature can be fitted into a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_neighbor = sales[[\"sale_price\", \"neighborhood\"]].groupby(['neighborhood'], as_index=False).mean()\n",
    "rank_neighbor.sort_values(\"sale_price\", inplace=True)\n",
    "ordering = {\n",
    "    neighbor: i for i, neighbor in enumerate(rank_neighbor[\"neighborhood\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is air-conditioning (`ac` = `\"Y\"`), encode it as `1`; otherwise `0`.\n",
    "\n",
    "Transform `zoning` into an ordinal variable, with `0` being the `Residential_Low_Density` , `1` being the `Residential_Medium_Density` and `2` being the `Residential_High_Density`.\n",
    "\n",
    "Transform `neighborhood` with the numbering of that neighborhood, e.g., `nb_01` is encoded as `1` and `nb_12` is encoded as `12`.\n",
    "\n",
    "Transform the `quality` and `condition` columns into ordinals, `poor` as `0`, `fair` as `1`, `good` as `2`, `excellent` as `3`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = {\n",
    "    \"ac\": {\"N\": 0, \"Y\": 1},\n",
    "    \"zoning\": {\"Residential_Low_Density\": 0, \"Residential_Medium_Density\": 1, \"Residential_High_Density\": 2},\n",
    "    \"neighborhood\": ordering,\n",
    "    \"quality\": {\"poor\": 0, \"fair\": 1, \"average\": 2, \"good\": 3, \"excellent\": 4},\n",
    "    \"condition\": {\"poor\": 0, \"fair\": 1, \"average\": 2, \"good\": 3, \"excellent\": 4}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the features as specified. I also decide to scale the `sale_price` using a log function and store it in the `log_sale_price` column so it looks more like a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.replace(encoding, inplace=True)\n",
    "sales[\"log_sale_price\"] = np.log(sales[\"sale_price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_test.replace(encoding, inplace=True)\n",
    "y_test = sales_test[\"sale_price\"]\n",
    "log_y_test = np.log(sales_test[\"sale_price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature matrix X of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sales.loc[:, \"year_sold\": \"condition\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature matrix X_test of the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sales_test.loc[:, \"year_sold\": \"condition\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True label vector y and scaled label vector log_y of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_y = sales[\"log_sale_price\"]\n",
    "y = sales[\"sale_price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Fitting and Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The polynomial regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'polynomialfeatures-1': PolynomialFeatures(degree=1, include_bias=False, interaction_only=False,\n",
       "                    order='C'),\n",
       " 'polynomialfeatures-2': PolynomialFeatures(degree=3, include_bias=False, interaction_only=False,\n",
       "                    order='C'),\n",
       " 'polynomialfeatures-3': PolynomialFeatures(degree=3, include_bias=False, interaction_only=False,\n",
       "                    order='C'),\n",
       " 'polynomialfeatures-4': PolynomialFeatures(degree=3, include_bias=False, interaction_only=False,\n",
       "                    order='C'),\n",
       " 'polynomialfeatures-5': PolynomialFeatures(degree=3, include_bias=False, interaction_only=False,\n",
       "                    order='C'),\n",
       " 'polynomialfeatures-6': PolynomialFeatures(degree=1, include_bias=False, interaction_only=False,\n",
       "                    order='C'),\n",
       " 'polynomialfeatures-7': PolynomialFeatures(degree=1, include_bias=False, interaction_only=False,\n",
       "                    order='C'),\n",
       " 'polynomialfeatures-8': PolynomialFeatures(degree=2, include_bias=False, interaction_only=False,\n",
       "                    order='C'),\n",
       " 'polynomialfeatures-9': PolynomialFeatures(degree=1, include_bias=False, interaction_only=False,\n",
       "                    order='C'),\n",
       " 'polynomialfeatures-10': PolynomialFeatures(degree=3, include_bias=False, interaction_only=False,\n",
       "                    order='C'),\n",
       " 'polynomialfeatures-11': PolynomialFeatures(degree=1, include_bias=False, interaction_only=False,\n",
       "                    order='C'),\n",
       " 'polynomialfeatures-12': PolynomialFeatures(degree=1, include_bias=False, interaction_only=False,\n",
       "                    order='C'),\n",
       " 'polynomialfeatures-13': PolynomialFeatures(degree=1, include_bias=False, interaction_only=False,\n",
       "                    order='C'),\n",
       " 'polynomialfeatures-14': PolynomialFeatures(degree=1, include_bias=False, interaction_only=False,\n",
       "                    order='C'),\n",
       " 'polynomialfeatures-15': PolynomialFeatures(degree=1, include_bias=False, interaction_only=False,\n",
       "                    order='C')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree_poly = 3\n",
    "\n",
    "poly_model  = make_pipeline(\n",
    "    make_column_transformer(\n",
    "        (PolynomialFeatures(degree=1, include_bias=False), [\"year_sold\"]),\n",
    "        (PolynomialFeatures(degree=degree_poly, include_bias=False), [\"year_built\"]),\n",
    "        (PolynomialFeatures(degree=degree_poly, include_bias=False), [\"lot_area\"]),\n",
    "        (PolynomialFeatures(degree=degree_poly, include_bias=False), [\"basement_area\"]),\n",
    "        (PolynomialFeatures(degree=degree_poly, include_bias=False), [\"living_area\"]),\n",
    "        (PolynomialFeatures(degree=1, include_bias=False), [\"full_bath\"]), \n",
    "        (PolynomialFeatures(degree=1, include_bias=False), [\"half_bath\"]), \n",
    "        (PolynomialFeatures(degree=2, include_bias=False), [\"bedroom\"]), \n",
    "        (PolynomialFeatures(degree=1, include_bias=False), [\"garage_cars\"]), \n",
    "        (PolynomialFeatures(degree=degree_poly, include_bias=False), [\"garage_area\"]),\n",
    "        (PolynomialFeatures(degree=1, include_bias=False), [\"ac\"]),\n",
    "        (PolynomialFeatures(degree=1, include_bias=False), [\"zoning\"]),\n",
    "        (PolynomialFeatures(degree=1, include_bias=False), [\"neighborhood\"]),\n",
    "        (PolynomialFeatures(degree=1, include_bias=False), [\"quality\"]),\n",
    "        (PolynomialFeatures(degree=1, include_bias=False), [\"condition\"]),\n",
    "    ),\n",
    "    LinearRegression(fit_intercept=True)\n",
    ")\n",
    "\n",
    "fit = poly_model.fit(X, log_y)\n",
    "poly_model.named_steps[\"columntransformer\"].named_transformers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.9478819370269775 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2430 out of 2430 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=2020, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('columntransformer',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('polynomialfeatures-1',\n",
       "                                                                         PolynomialFeatures(degree=1,\n",
       "                                                                                            include_bias=False,\n",
       "                                                                                            interaction_only=False,\n",
       "                                                                                            order='C'...\n",
       "                         'columntransformer__polynomialfeatures-3__degree': array([1, 2, 3]),\n",
       "                         'columntransformer__polynomialfeatures-4__degree': array([1, 2, 3]),\n",
       "                         'columntransformer__polynomialfeatures-5__degree': array([1, 2, 3]),\n",
       "                         'columntransformer__polynomialfeatures-8__degree': array([1, 2])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_root_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'columntransformer__polynomialfeatures-2__degree': np.arange(1, degree_poly + 1),\n",
    "    'columntransformer__polynomialfeatures-3__degree': np.arange(1, degree_poly + 1),\n",
    "    'columntransformer__polynomialfeatures-4__degree': np.arange(1, degree_poly + 1),\n",
    "    'columntransformer__polynomialfeatures-5__degree': np.arange(1, degree_poly + 1),\n",
    "    'columntransformer__polynomialfeatures-8__degree': np.arange(1, 3),\n",
    "    'columntransformer__polynomialfeatures-10__degree': np.arange(1, degree_poly + 1),\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "grid_search = GridSearchCV(poly_model, parameters, \n",
    "                           cv=KFold(5, True, random_state=2020), \n",
    "                           scoring=\"neg_root_mean_squared_error\", \n",
    "                           verbose=1).fit(X, log_y)\n",
    "print((time.time() - start)/ 60, \"minutes\")\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best index:  455\n",
      "best param:  {'columntransformer__polynomialfeatures-10__degree': 3, 'columntransformer__polynomialfeatures-2__degree': 3, 'columntransformer__polynomialfeatures-3__degree': 2, 'columntransformer__polynomialfeatures-4__degree': 1, 'columntransformer__polynomialfeatures-5__degree': 3, 'columntransformer__polynomialfeatures-8__degree': 2}\n",
      "best score:  -0.11163763369887365\n"
     ]
    }
   ],
   "source": [
    "print(\"best index: \", grid_search.best_index_)\n",
    "print(\"best param: \", grid_search.best_params_)\n",
    "print(\"best score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 Best Coefficients [-1.21485589e-03  4.00101126e+00 -2.06134021e-03  3.54122877e-07\n",
      "  7.09056782e-06 -3.58710327e-11  1.59383073e-04  7.20428556e-04\n",
      " -1.90450813e-07  2.68390646e-11 -1.63277371e-02  1.09514557e-02\n",
      "  1.43220645e-02 -8.04598949e-03  2.00172427e-02  4.07605671e-04\n",
      " -4.85158920e-07  2.37135186e-10  8.73304598e-02 -3.87181126e-02\n",
      "  9.44997669e-03  9.85887136e-02  1.18129664e-01]\n",
      "Best Intercept -2576.8183951853584\n"
     ]
    }
   ],
   "source": [
    "print(len(grid_search.best_estimator_.named_steps['linearregression'].coef_), \"Best Coefficients\", \n",
    "      grid_search.best_estimator_.named_steps['linearregression'].coef_)\n",
    "print(\"Best Intercept\", grid_search.best_estimator_.named_steps['linearregression'].intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training log rmse 0.1085419333345432\n"
     ]
    }
   ],
   "source": [
    "log_train_prediction = grid_search.best_estimator_.predict(X)\n",
    "print(\"training log rmse\", np.sqrt(mean_squared_error(log_y, log_train_prediction )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training rmse 20028.210483804847\n"
     ]
    }
   ],
   "source": [
    "print(\"training rmse\", np.sqrt(mean_squared_error(y, np.exp(log_train_prediction ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log cross validation rmse [0.11190339 0.10927243 0.11412519 0.11894092 0.10394623]\n"
     ]
    }
   ],
   "source": [
    "print(\"log cross validation rmse\", \n",
    "      -1 * cross_val_score(grid_search.best_estimator_, X, log_y, \n",
    "                           cv=KFold(5, True, random_state=2020), scoring=\"neg_root_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing log rmse 0.11856919114776257\n"
     ]
    }
   ],
   "source": [
    "log_test_prediction = grid_search.best_estimator_.predict(X_test)\n",
    "print(\"testing log rmse\", np.sqrt(mean_squared_error(log_y_test, log_test_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing rmse 22717.48662783491\n"
     ]
    }
   ],
   "source": [
    "print(\"testing rmse\", np.sqrt(mean_squared_error(y_test, np.exp(log_test_prediction))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
